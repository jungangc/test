{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Bu5mKQbMEQ_"
   },
   "source": [
    "## Project 2       Jungang (Gordon) Chen            UIN: 5280097929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBU2xsA8MERA"
   },
   "source": [
    "## 1)  Load the text dataset and text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "id": "CNht1omtMERB"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elEoWObFMERC",
    "outputId": "232dfdb9-332f-4f6e-975b-11ef58f3c046",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "input_sequence = pickle.load(open('DS_5_train_input', 'rb'))\n",
    "output_sequence = pickle.load(open('DS_5_train_output', 'rb'))\n",
    "print(type(input_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-MOaaHMMERD",
    "outputId": "1a2b2bb2-a901-41dd-a162-d81d8e7a11ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a f b e a j a h a g b e b d a e c f c g a j b d a j b d a h c e b d c g a g a k c e b e a d b e b g b e b f ', '[start] b e b e b d a g e f c f a e h c g a h g i j b d b d c e b d c g a h ed ee ef c e b e a k eh ei b e b g a d ek el a g ej em a j m eg fd b e a j l fe ff b f a j k fg fh a f d fi  [end]')\n"
     ]
    }
   ],
   "source": [
    "text_pairs = []\n",
    "for line in range(len(input_sequence)):\n",
    "    inputish  = input_sequence[line]\n",
    "    outputish = \"[start] \" + output_sequence[line] + \" [end]\"\n",
    "    text_pairs.append((inputish, outputish))\n",
    "\n",
    "import random\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMgmvon4eKXH",
    "outputId": "3022dfa0-539d-4d60-b055-9edf3a7a9cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "print(len(text_pairs))\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TImKx8WBJiMS",
    "outputId": "eafd0cd4-ed74-4d63-b2f8-24a6993d8445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "src_vocab_size = 50\n",
    "tgt_vocab_size = 50\n",
    "sequence_length = 100\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=src_vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=tgt_vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length+1, \n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "train_inputish_texts = [pair[0] for pair in train_pairs]\n",
    "train_outputish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_inputish_texts)\n",
    "target_vectorization.adapt(train_outputish_texts)\n",
    "print(len(source_vectorization.get_vocabulary()))\n",
    "\n",
    "print(len(target_vectorization.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nR11xxwKJiMf",
    "outputId": "3ff8ca31-df1d-4e92-e41a-7a265ee46ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CacheDataset element_spec=({'english': TensorSpec(shape=(None, 100), dtype=tf.int64, name=None), 'spanish': TensorSpec(shape=(None, 100), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 100), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"spanish\": spa[:, :-1],\n",
    "    }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n",
    "\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1qZktTgJiMw",
    "outputId": "19ae7e0d-6769-4fdf-ad16-eb7d1d9366bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (16, 100)\n",
      "inputs['spanish'].shape: (16, 100)\n",
      "targets.shape: (16, 100)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFiO_M1FJiMx"
   },
   "source": [
    "## 2) Build a transformer model with a stack of 2 encoder and 3 decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "id": "6Ni-1zLOJiMx"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "id": "fCbbkJhpNJ3_"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "id": "bSd4miDzJiMz"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "id": "UmBJWX24WxCs"
   },
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "dense_dim = 512\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, src_vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, tgt_vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(tgt_vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lzjZ5hlGJiM0",
    "outputId": "54eddf72-9dd3-4424-b8a4-e571cb395352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 17s 43ms/step - loss: 1.3770 - accuracy: 0.3043 - val_loss: 0.9866 - val_accuracy: 0.4040\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.9653 - accuracy: 0.4255 - val_loss: 0.8357 - val_accuracy: 0.4911\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.8214 - accuracy: 0.4957 - val_loss: 0.7000 - val_accuracy: 0.5534\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.7360 - accuracy: 0.5395 - val_loss: 0.6550 - val_accuracy: 0.5818\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.6840 - accuracy: 0.5691 - val_loss: 0.6505 - val_accuracy: 0.5867\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.6292 - accuracy: 0.5999 - val_loss: 0.6134 - val_accuracy: 0.6048\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.5788 - accuracy: 0.6312 - val_loss: 0.6065 - val_accuracy: 0.6172\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 9s 39ms/step - loss: 0.5443 - accuracy: 0.6570 - val_loss: 0.5065 - val_accuracy: 0.6791\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.4967 - accuracy: 0.6843 - val_loss: 0.4441 - val_accuracy: 0.7049\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.4688 - accuracy: 0.7046 - val_loss: 0.5228 - val_accuracy: 0.6855\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.4375 - accuracy: 0.7242 - val_loss: 0.4162 - val_accuracy: 0.7304\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.4091 - accuracy: 0.7422 - val_loss: 0.3788 - val_accuracy: 0.7539\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.3850 - accuracy: 0.7586 - val_loss: 0.7740 - val_accuracy: 0.6258\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.3644 - accuracy: 0.7737 - val_loss: 0.4476 - val_accuracy: 0.7193\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.3416 - accuracy: 0.7879 - val_loss: 0.3165 - val_accuracy: 0.7951\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.3205 - accuracy: 0.8016 - val_loss: 0.3077 - val_accuracy: 0.8041\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.3026 - accuracy: 0.8147 - val_loss: 0.2600 - val_accuracy: 0.8341\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.2835 - accuracy: 0.8266 - val_loss: 0.2580 - val_accuracy: 0.8406\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.2655 - accuracy: 0.8383 - val_loss: 0.2674 - val_accuracy: 0.8305\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.2496 - accuracy: 0.8512 - val_loss: 0.2417 - val_accuracy: 0.8535\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.2310 - accuracy: 0.8620 - val_loss: 0.2761 - val_accuracy: 0.8301\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.2199 - accuracy: 0.8700 - val_loss: 0.1889 - val_accuracy: 0.8849\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.2055 - accuracy: 0.8789 - val_loss: 0.1916 - val_accuracy: 0.8836\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.1929 - accuracy: 0.8885 - val_loss: 0.2199 - val_accuracy: 0.8732\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1842 - accuracy: 0.8944 - val_loss: 0.2163 - val_accuracy: 0.8693\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.1753 - accuracy: 0.9001 - val_loss: 0.1762 - val_accuracy: 0.8964\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.1641 - accuracy: 0.9065 - val_loss: 0.2558 - val_accuracy: 0.8611\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1570 - accuracy: 0.9104 - val_loss: 0.1784 - val_accuracy: 0.8948\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1472 - accuracy: 0.9163 - val_loss: 0.1403 - val_accuracy: 0.9165\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.1439 - accuracy: 0.9199 - val_loss: 0.1521 - val_accuracy: 0.9129\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.1358 - accuracy: 0.9245 - val_loss: 0.3139 - val_accuracy: 0.8466\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1290 - accuracy: 0.9282 - val_loss: 0.1355 - val_accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1246 - accuracy: 0.9307 - val_loss: 0.1277 - val_accuracy: 0.9262\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.1181 - accuracy: 0.9348 - val_loss: 0.1349 - val_accuracy: 0.9255\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1155 - accuracy: 0.9372 - val_loss: 0.1247 - val_accuracy: 0.9274\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1099 - accuracy: 0.9397 - val_loss: 0.1195 - val_accuracy: 0.9304\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1047 - accuracy: 0.9424 - val_loss: 0.1918 - val_accuracy: 0.9002\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.1016 - accuracy: 0.9448 - val_loss: 0.1633 - val_accuracy: 0.9093\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0973 - accuracy: 0.9472 - val_loss: 0.1090 - val_accuracy: 0.9397\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0929 - accuracy: 0.9497 - val_loss: 0.1051 - val_accuracy: 0.9392\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0912 - accuracy: 0.9504 - val_loss: 0.1047 - val_accuracy: 0.9425\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0870 - accuracy: 0.9535 - val_loss: 0.1131 - val_accuracy: 0.9381\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0836 - accuracy: 0.9557 - val_loss: 0.1257 - val_accuracy: 0.9328\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0822 - accuracy: 0.9559 - val_loss: 0.1360 - val_accuracy: 0.9256\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0777 - accuracy: 0.9587 - val_loss: 0.1083 - val_accuracy: 0.9397\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0769 - accuracy: 0.9603 - val_loss: 0.2370 - val_accuracy: 0.8933\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0741 - accuracy: 0.9615 - val_loss: 0.0961 - val_accuracy: 0.9483\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0714 - accuracy: 0.9631 - val_loss: 0.1311 - val_accuracy: 0.9324\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0694 - accuracy: 0.9641 - val_loss: 0.0983 - val_accuracy: 0.9467\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0663 - accuracy: 0.9654 - val_loss: 0.1250 - val_accuracy: 0.9344\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0636 - accuracy: 0.9667 - val_loss: 0.0945 - val_accuracy: 0.9507\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0626 - accuracy: 0.9674 - val_loss: 0.0867 - val_accuracy: 0.9525\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0643 - accuracy: 0.9671 - val_loss: 0.0979 - val_accuracy: 0.9487\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0577 - accuracy: 0.9711 - val_loss: 0.0977 - val_accuracy: 0.9482\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0575 - accuracy: 0.9711 - val_loss: 0.0973 - val_accuracy: 0.9504\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0563 - accuracy: 0.9713 - val_loss: 0.0955 - val_accuracy: 0.9510\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0526 - accuracy: 0.9733 - val_loss: 0.1110 - val_accuracy: 0.9457\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0531 - accuracy: 0.9733 - val_loss: 0.0920 - val_accuracy: 0.9552\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0532 - accuracy: 0.9735 - val_loss: 0.1028 - val_accuracy: 0.9480\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0472 - accuracy: 0.9760 - val_loss: 0.0852 - val_accuracy: 0.9569\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0497 - accuracy: 0.9753 - val_loss: 0.0946 - val_accuracy: 0.9543\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0473 - accuracy: 0.9764 - val_loss: 0.0711 - val_accuracy: 0.9654\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0461 - accuracy: 0.9770 - val_loss: 0.0889 - val_accuracy: 0.9566\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0458 - accuracy: 0.9776 - val_loss: 0.0676 - val_accuracy: 0.9661\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0437 - accuracy: 0.9779 - val_loss: 0.1059 - val_accuracy: 0.9524\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0421 - accuracy: 0.9792 - val_loss: 0.0944 - val_accuracy: 0.9542\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0402 - accuracy: 0.9801 - val_loss: 0.1080 - val_accuracy: 0.9497\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0410 - accuracy: 0.9800 - val_loss: 0.0781 - val_accuracy: 0.9627\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0407 - accuracy: 0.9802 - val_loss: 0.1602 - val_accuracy: 0.9283\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0384 - accuracy: 0.9812 - val_loss: 0.0737 - val_accuracy: 0.9660\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0388 - accuracy: 0.9811 - val_loss: 0.1052 - val_accuracy: 0.9528\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0370 - accuracy: 0.9821 - val_loss: 0.1015 - val_accuracy: 0.9530\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0357 - accuracy: 0.9825 - val_loss: 0.0732 - val_accuracy: 0.9661\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0365 - accuracy: 0.9824 - val_loss: 0.0637 - val_accuracy: 0.9686\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0350 - accuracy: 0.9833 - val_loss: 0.0633 - val_accuracy: 0.9701\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0344 - accuracy: 0.9836 - val_loss: 0.0747 - val_accuracy: 0.9637\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0351 - accuracy: 0.9831 - val_loss: 0.0872 - val_accuracy: 0.9588\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0330 - accuracy: 0.9843 - val_loss: 0.0744 - val_accuracy: 0.9647\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0324 - accuracy: 0.9849 - val_loss: 0.0669 - val_accuracy: 0.9704\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0331 - accuracy: 0.9841 - val_loss: 0.0709 - val_accuracy: 0.9666\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0314 - accuracy: 0.9849 - val_loss: 0.0833 - val_accuracy: 0.9607\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0306 - accuracy: 0.9851 - val_loss: 0.0787 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0315 - accuracy: 0.9853 - val_loss: 0.0685 - val_accuracy: 0.9694\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0306 - accuracy: 0.9853 - val_loss: 0.0656 - val_accuracy: 0.9677\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0286 - accuracy: 0.9866 - val_loss: 0.0718 - val_accuracy: 0.9682\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0310 - accuracy: 0.9853 - val_loss: 0.0625 - val_accuracy: 0.9717\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0286 - accuracy: 0.9866 - val_loss: 0.0804 - val_accuracy: 0.9618\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0278 - accuracy: 0.9867 - val_loss: 0.0805 - val_accuracy: 0.9634\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0281 - accuracy: 0.9869 - val_loss: 0.0651 - val_accuracy: 0.9707\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0269 - accuracy: 0.9872 - val_loss: 0.0731 - val_accuracy: 0.9675\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0276 - accuracy: 0.9873 - val_loss: 0.0628 - val_accuracy: 0.9718\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0267 - accuracy: 0.9875 - val_loss: 0.0607 - val_accuracy: 0.9737\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0267 - accuracy: 0.9878 - val_loss: 0.0719 - val_accuracy: 0.9683\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0263 - accuracy: 0.9876 - val_loss: 0.0583 - val_accuracy: 0.9722\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0263 - accuracy: 0.9879 - val_loss: 0.1754 - val_accuracy: 0.9327\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0259 - accuracy: 0.9879 - val_loss: 0.0850 - val_accuracy: 0.9622\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0251 - accuracy: 0.9886 - val_loss: 0.0705 - val_accuracy: 0.9682\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0249 - accuracy: 0.9884 - val_loss: 0.0698 - val_accuracy: 0.9684\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0252 - accuracy: 0.9885 - val_loss: 0.1021 - val_accuracy: 0.9586\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0235 - accuracy: 0.9894 - val_loss: 0.0597 - val_accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda75503c50>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"artificial_text_translation.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "transformer.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model Accuracy by randomly selecting 20 true/prediction testing sentences and compare them token by token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOUOjN5rV8VA",
    "outputId": "267b74e6-b420-4d09-cd6a-f500ec2a8da0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7979966611018364\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 100\n",
    "\n",
    "def decode_sequence(input_sentence, model):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = model(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "def transform_format(true_output_sequence, pred_sequence):\n",
    "    true_output_sequence = true_output_sequence.split()\n",
    "    pred_sequence  = pred_sequence.split()\n",
    "    true_output_sequence.remove('[start]')\n",
    "    true_output_sequence.remove('[end]')\n",
    "    pred_sequence.remove('[start]')\n",
    "    pred_sequence.remove('[end]')\n",
    "    return true_output_sequence, pred_sequence\n",
    "\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_spa_texts = [pair[1] for pair in test_pairs]\n",
    "\n",
    "count_total = 0\n",
    "count_match =0 \n",
    "for i in np.random.randint(len(test_eng_texts),size=20):\n",
    "    input_sequence = test_eng_texts[i]\n",
    "    true_output_sequence = test_spa_texts[i]    \n",
    "    pred_sequence  = decode_sequence(input_sequence,transformer)\n",
    "    \n",
    "    true_output_sequence, pred_sequence=transform_format(true_output_sequence, pred_sequence)\n",
    "    count_total+=len(true_output_sequence)\n",
    "    for i, token in enumerate(pred_sequence):\n",
    "        if i<len(true_output_sequence):\n",
    "            if token == true_output_sequence[i]:\n",
    "            count_match+=1\n",
    "        else:\n",
    "            break\n",
    "  # print(count_match)\n",
    "  # print(len(true_output_sequence))\n",
    "  # print(count_match/len(true_output_sequence))\n",
    "\n",
    "print(count_match/count_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Reload the model and test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2s11FzN0e7V",
    "outputId": "058c9c0d-af57-463d-c09c-250bdf5dad64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7939581719597212\n"
     ]
    }
   ],
   "source": [
    "# At loading time, register the custom objects with a `custom_object_scope`:\n",
    "load_model = keras.models.load_model(\"artificial_text_translation.keras\", custom_objects={\n",
    "'TransformerEncoder': TransformerEncoder,\n",
    "'TransformerDecoder': TransformerDecoder,\n",
    "'PositionalEmbedding': PositionalEmbedding\n",
    "})\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_spa_texts = [pair[1] for pair in test_pairs]\n",
    "\n",
    "count_total = 0\n",
    "count_match = 0 \n",
    "for i in np.random.randint(len(test_eng_texts),size=20):\n",
    "    input_sequence = test_eng_texts[i]\n",
    "    true_output_sequence = test_spa_texts[i]    \n",
    "    pred_sequence  = decode_sequence(input_sequence,load_model)\n",
    "\n",
    "    true_output_sequence, pred_sequence=transform_format(true_output_sequence, pred_sequence)\n",
    "    count_total+=len(true_output_sequence)\n",
    "    for i, token in enumerate(pred_sequence):\n",
    "        if i<len(true_output_sequence):\n",
    "            if token == true_output_sequence[i]:\n",
    "                count_match+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "print(count_match/count_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cvrl73zJiM2"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "id": "my-O45OuJiM2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_2_Jungang_(Gordon)_Chen_528007929.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
